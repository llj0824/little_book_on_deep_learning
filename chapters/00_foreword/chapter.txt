--- Page 8 ---
Foreword
The current period of progress in artificial in-
telligence was triggered when Krizhevsky et al.
[2012] demonstrated that anartificial neural net-
work designed twenty years earlier [LeCun et al.,
1989] could outperform complex state-of-the-
art image recognition methods by a huge mar-
gin, simply by being a hundred times larger and
trained on a dataset similarly scaled up.
This breakthrough was made possible thanks to
Graphical Processing Units (GPUs), highly par-
allel consumer-grade computing devices devel-
oped for real-time image synthesis and repur-
posed for artificial neural networks.
Since then, under the umbrella term of “deep
learning,” innovations in the structures of these
networks, the strategies to train them, and ded-
icated hardware have allowed for an exponen-
tial increase in both their size and the quantity
of training data they take advantage of [Sevilla
8

--- Page 9 ---
et al., 2022]. This has resulted in a wave of suc-
cessful applications across technical domains,
from computer vision and robotics to speech
processing, and since 2020 in the development
of Large Language Models with general proto-
reasoning capabilities [Chowdhery et al., 2022].
Althoughthebulkofdeeplearningisnotdifficult
to understand, it combines diverse components
such as linear algebra, calculus, probabilities, op-
timization, signal processing, programming, al-
gorithmics, and high-performance computing,
making it complicated to learn.
Instead of trying to be exhaustive, this little book
is limited to the background necessary to under-
stand a few important models. This proved to
be a popular approach, resulting in more than
500,000 downloads of the PDF file in the 12
months following its announcement on Twitter.
If you did not get this book from its official URL
https://fleuret.org/public/lbdl.pdf
please do so, to allow the estimation of the num-
ber of readers.
François Fleuret,
May 19, 2024
9
